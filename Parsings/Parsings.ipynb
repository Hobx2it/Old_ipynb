{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, urlretrieve\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import requests \n",
    "from fake_headers import Headers \n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балтздрав"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baltzdrav_services_list = {}  # сюда запишем все страницы для поиска\n",
    "\n",
    "resp = urlopen('http://baltzdrav.ru/services') # скачиваем файл\n",
    "html = resp.read().decode('utf8') # считываем содержимое\n",
    "soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "\n",
    "for link in soup.find_all('li'):\n",
    "    if link.has_attr('class') and \"uk-none\" in link.get('class'):\n",
    "        for a in link.find_all('a', href=True):\n",
    "            baltzdrav_services_list.setdefault(a.text, a.get('href'))\n",
    "            \n",
    "adress = 'http://baltzdrav.ru'\n",
    "baltzdrav = {'code' : [],\n",
    "            'description' : [],\n",
    "            'price' : [],\n",
    "            'department' : []}\n",
    "\n",
    "for key, val in baltzdrav_services_list.items():\n",
    "\n",
    "    resp = urlopen(adress + val) # скачиваем файл\n",
    "    html = resp.read().decode('utf8') # считываем содержимое\n",
    "    soup = BeautifulSoup(html, 'html.parser') # делаем суп\n",
    "    cnt = 0\n",
    "    for link in soup.find_all('td'):\n",
    "        if link.has_attr('class'):\n",
    "            attribute = link.get('class')\n",
    "            if re.search(r'xl\\d{2}', str(attribute)) and re.search(r'^\\d{5}$', link.text):\n",
    "                baltzdrav['code'].append(link.text)\n",
    "                baltzdrav['description'].append(link.find_next('td').text)\n",
    "                baltzdrav['price'].append(link.find_next('td').find_next('td').text)\n",
    "                baltzdrav['department'].append(key) \n",
    "\n",
    "\n",
    "    \n",
    "data_baltzdrav = pd.DataFrame.from_dict(baltzdrav)\n",
    "data_baltzdrav.columns = ['Код', 'Описание услуги', 'Цена в рублях', 'Отдел']\n",
    "data_baltzdrav['Цена в рублях'] = data_baltzdrav['Цена в рублях'].apply(lambda x: float(x.replace(' ', '')))\n",
    "data_baltzdrav.to_excel(r'C:\\Users\\AmanovRA\\Anaconda3\\Work-work\\Parsings\\Балтздрав\\Baltzdrav_' + str(datetime.date(datetime.today())) + '.xlsx')    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скандинавия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avaclinic = {'name' : [],\n",
    "            'price' : []}\n",
    "\n",
    "\n",
    "\n",
    "resp = urlopen('https://avaclinic.ru/prices/') \n",
    "html = resp.read().decode('utf8') \n",
    "soup = BeautifulSoup(html, 'html.parser') \n",
    "lastpage = 0 \n",
    "pattern = r'/prices/\\?PAGEN_1=(\\d+)'\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    if link.has_attr('href') and '/prices/?PAGEN_1=' in link.get('href'):\n",
    "        if int(re.search(pattern, link.get('href')).groups(1)[0]) > lastpage:\n",
    "            lastpage = int(re.search(pattern, link.get('href')).groups(1)[0]) # нашли последнюю страницу в прайсах из ul pagination чтобы знать до какой парсить\n",
    "\n",
    "            \n",
    "adress = 'https://avaclinic.ru/prices/?PAGEN_1='\n",
    "cnt = 1\n",
    "          \n",
    "\n",
    "while cnt <= lastpage:\n",
    "    resp = urlopen(adress + str(cnt)) \n",
    "    html = resp.read().decode('utf8') \n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "\n",
    "    for link in soup.find_all('p'):\n",
    "        if link.has_attr('class') and link.get('class')[0] == 'name':\n",
    "            avaclinic['name'].append(link.text)\n",
    "        if link.has_attr('class') and link.get('class')[0] == \"price\":\n",
    "            avaclinic['price'].append(float(''.join([i for i in link.text if i.isdigit()])))\n",
    "            \n",
    "    cnt += 1           \n",
    "data_avaclinic = pd.DataFrame.from_dict(avaclinic)\n",
    "data_avaclinic.columns = ['Описание услуги', 'Цена в рублях']\n",
    "data_avaclinic.to_excel(r'C:\\Users\\AmanovRA\\Anaconda3\\Work-work\\Parsings\\Скандинавия\\Scandinav_' + str(datetime.date(datetime.today())) + '.xlsx')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СМ-Клиника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "smclinic = {'name' : [],\n",
    "            'price' : []}\n",
    "\n",
    "resp = urlopen('https://www.smclinic-spb.ru/uslugi/tseny-i-stoimost-uslug')\n",
    "html = resp.read().decode('utf8') \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for link in soup.find_all('td'):\n",
    "    if link.has_attr('class') and link.get('class')[0] == 'price' and len(link.get('class')) == 1:\n",
    "        smclinic['name'].append(link.find_previous('td').text)\n",
    "        smclinic['price'].append(float(''.join([i for i in link.text if i.isdigit()])))\n",
    "\n",
    "data_smclinic = pd.DataFrame.from_dict(smclinic)\n",
    "data_smclinic.columns = ['Описание услуги', 'Цена в рублях']\n",
    "data_smclinic.to_excel(r'C:\\Users\\AmanovRA\\Anaconda3\\Work-work\\Parsings\\СМ_Клиник\\SM_clinic_' + str(datetime.date(datetime.today())) + '.xlsx')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немецкая семейная клиника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = {'departments' : [],\n",
    "             'service' : [],\n",
    "             'price' : []}\n",
    "pattern1 = r'(.+%)(.+)'  # убрать цифры с процентами\n",
    "pattern2 = r'[^\\d ]'\n",
    "home_pages = ['https://german.clinic', 'https://german.dental']\n",
    "\n",
    "for index_home_page, home_page in enumerate(home_pages):\n",
    "    if index_home_page == 0:\n",
    "        resp = urlopen(home_page)\n",
    "        html = resp.read().decode('utf8') \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for ul in soup.find_all('ul', \"services__list\"):\n",
    "            for li in ul.find_all('li'):\n",
    "                link = li.find('a')\n",
    "                if '//' not in link.get('href'):\n",
    "                    age = 'children' if 'children' in link.get('href') else 'adult' if 'adult' in link.get('href') else ''\n",
    "                    try: # некоторые ссылки битые на услуги\n",
    "                        resp = urlopen(home_page + link.get('href'))\n",
    "                    except:\n",
    "                        continue\n",
    "                    html = resp.read().decode('utf8') \n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    if soup.find('table', \"textpage__table\"):\n",
    "                        table = soup.find('table', \"textpage__table\")\n",
    "                        for tr in table.find_all('tr'):\n",
    "                            if tr.find('td'):\n",
    "                                if (len(tr.find_all('td'))) == 1:\n",
    "                                    continue\n",
    "                                td = tr.find('td')\n",
    "                                td_price = td.find_next('td').text\n",
    "                                if td_price == '':\n",
    "                                    continue\n",
    "                                directions['service'].append(td.text)     \n",
    "                                td_price = re.sub(pattern1, r'\\2', td_price)\n",
    "                                td_price = re.sub(pattern2, '', td_price).strip(' ').split()\n",
    "                                tempprices = []\n",
    "                                for i, j in enumerate(td_price[::2]):\n",
    "                                    if len(j) in (1, 2):\n",
    "                                        tempprices.append(td_price[i * 2] + td_price[i * 2 + 1])\n",
    "                                    elif len(td_price) == 1:\n",
    "                                        tempprices.append(j)\n",
    "                                    elif len(j) >= 4:\n",
    "                                        tempprices.append(j)               \n",
    "                                directions['price'].append(tempprices)\n",
    "                                directions['departments'].append(link.text + ' ' + age)\n",
    "    else:\n",
    "        resp = urlopen(home_page)\n",
    "        html = resp.read().decode('utf8') \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for li in soup.find_all('li', \"topmenu__item\"):\n",
    "            if \"data-rel\" in li.find_next('a').attrs:\n",
    "                ul = li.find_next('a', {\"data-rel\" : \"#service\"}).find_next('ul')\n",
    "                for service_li in ul.find_all('li'):\n",
    "                    link = service_li.find_next('a')\n",
    "                    age = 'children' if 'children' in link.get('href') else 'adult' if 'adult' in link.get('href') else ''\n",
    "                    try: # некоторые ссылки битые на услуги\n",
    "                        resp = urlopen(home_page + link.get('href'))\n",
    "                    except:\n",
    "                        continue\n",
    "                    html = resp.read().decode('utf8') \n",
    "                    soup = BeautifulSoup(html, 'html.parser')\n",
    "                    if soup.find('table', \"textpage__table\"):\n",
    "                        table = soup.find('table', \"textpage__table\")\n",
    "                        for tr in table.find_all('tr'):\n",
    "                            if tr.find('td'):\n",
    "                                if (len(tr.find_all('td'))) == 1:\n",
    "                                    continue\n",
    "                                td = tr.find('td')\n",
    "                                td_price = td.find_next('td').text\n",
    "                                if td_price == '':\n",
    "                                    continue\n",
    "                                directions['service'].append(td.text)     \n",
    "                                td_price = re.sub(pattern1, r'\\2', td_price)\n",
    "                                td_price = re.sub(pattern2, '', td_price).strip(' ').split()\n",
    "                                tempprices = []\n",
    "                                for i, j in enumerate(td_price[::2]):\n",
    "                                    if len(j) in (1, 2):\n",
    "                                        tempprices.append(td_price[i * 2] + td_price[i * 2 + 1])\n",
    "                                    elif len(td_price) == 1:\n",
    "                                        tempprices.append(j)\n",
    "                                    elif len(j) >= 4:\n",
    "                                        tempprices.append(j)               \n",
    "                                directions['price'].append(tempprices)\n",
    "                                directions['departments'].append(link.text + ' ' + age)        \n",
    "                        \n",
    "\n",
    "data = pd.DataFrame(directions)\n",
    "\n",
    "def join_list(lst):\n",
    "    if type(lst) == list and len(lst) > 1:\n",
    "        return '; '.join([i for i in lst])\n",
    "    elif len(lst) == 1 and lst[0].isnumeric():\n",
    "        return int(lst[0])\n",
    "    \n",
    "data.price = data.price.apply(join_list)\n",
    "\n",
    "\n",
    "data.to_excel(r'C:\\Users\\AmanovRA\\Anaconda3\\Work-work\\Parsings\\Немецкая_семейная\\German_clinic_' + str(datetime.date(datetime.today())) + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
